import streamlit as st
import pandas as pd
import joblib
import re
from transformers import AutoTokenizer, AutoModel
import torch

# ---- ØªØ­Ù…ÙŠÙ„ Ù†Ù…ÙˆØ°Ø¬ Decision Tree ----
dt_model = joblib.load("decision_tree_model.pkl")

# ---- ØªØ­Ù…ÙŠÙ„ Ù†Ù…ÙˆØ°Ø¬ AraBERT ----
arabert_clf = joblib.load("arabert_classifier.pkl")
tokenizer = AutoTokenizer.from_pretrained("aubmindlab/bert-base-arabertv2")
arabert_model = AutoModel.from_pretrained("aubmindlab/bert-base-arabertv2")
arabert_model.eval()

# ---- Ø¯ÙˆØ§Ù„ Ù…Ø³Ø§Ø¹Ø¯Ø© ----
def preprocess_arabic_text(text):
    text = re.sub(r'[^\u0600-\u06FF\s]', '', str(text))
    text = re.sub(r'[\u064B-\u0652\u0670\u0640]', '', text)
    text = re.sub(r'\s+', ' ', text).strip()
    return text

def heuristic_risk_level(text):
    high_keywords = ["Ø¹Ù†Ù","Ø¹Ù†ÙŠÙ","ØªÙ†Ù…Ø±","ØªÙ‡Ø¯ÙŠØ¯","Ø§ÙƒØªØ¦Ø§Ø¨","Ø§Ù†ØªØ­Ø§Ø±","Ù…Ø®Ø¯Ø±Ø§Øª","Ø§Ø¹ØªØ¯Ø§Ø¡","Ø¥ÙŠØ°Ø§Ø¡"]
    medium_keywords = ["Ù‚Ù„Ù‚","ØªÙˆØªØ±","Ø§Ù†Ø¹Ø²Ø§Ù„","Ù…Ø´Ø§ÙƒÙ„ Ø£Ø³Ø±ÙŠØ©","Ù…Ø´Ø§ÙƒÙ„ Ø¹Ø§Ø¦Ù„ÙŠØ©","Ø­Ø²Ù†","ØªØ±Ø§Ø¬Ø¹","Ø¹Ø¯ÙˆØ§Ù†ÙŠØ©"]
    if any(kw in text for kw in high_keywords):
        return "high"
    if any(kw in text for kw in medium_keywords):
        return "moderate"
    return "low"

def get_embeddings(texts, tokenizer, model, max_len=128):
    inputs = tokenizer(
        texts.tolist(),
        return_tensors="pt",
        padding=True,
        truncation=True,
        max_length=max_len
    )
    with torch.no_grad():
        outputs = model(**inputs)
    embeddings = outputs.last_hidden_state.mean(dim=1)
    return embeddings.numpy()

def get_risk_level(note):
    note_clean = preprocess_arabic_text(note)
    heuristic = heuristic_risk_level(note_clean)
    if heuristic != "low":
        return heuristic
    emb = get_embeddings(pd.Series([note_clean]), tokenizer, arabert_model)
    return arabert_clf.predict(emb)[0]

# ---- ØªØ­Ù…ÙŠÙ„ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø·Ù„Ø§Ø¨ Ø§Ù„Ø³Ø§Ø¨Ù‚ÙŠÙ† Ø£Ùˆ Ø¥Ù†Ø´Ø§Ø¡ DataFrame ÙØ§Ø±Øº ----
try:
    df_students = pd.read_csv("students_data.csv", dtype=str)
except FileNotFoundError:
    df_students = pd.DataFrame(columns=[
        "Ø§Ù„Ø§Ø³Ù…", "Ø§Ù„Ø¬Ù†Ø³", "Ø§Ù„Ø±Ù‚Ù…_Ø§Ù„ÙˆØ·Ù†ÙŠ","Ø§Ù„Ø¹Ù…Ø±","Ø§Ù„Ø­Ø¶ÙˆØ±",
        "Ø§Ù„Ù…Ø¹Ø¯Ù„_Ø§Ù„Ø£ÙƒØ§Ø¯ÙŠÙ…ÙŠ","Ø¹Ø¯Ø¯_Ø§Ù„Ø¬Ù„Ø³Ø§Øª","Ù…Ù„Ø§Ø­Ø¸Ø§Øª",
        "Ù…Ø³ØªÙˆÙ‰_Ø§Ù„Ø®Ø·ÙˆØ±Ø©","RiskLvlNum","Ø§Ù„Ø¥Ø¬Ø±Ø§Ø¡","Ø§Ù„ØªÙˆØµÙŠØ§Øª"
    ])

# ---- Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„ØµÙØ­Ø© ----
st.set_page_config(
    page_title="Ù…Ø¹Ø§Ù‹ Ù„ØªØ¹Ø²ÙŠØ² Ø§Ù„ØµØ­Ø© Ø§Ù„Ù†ÙØ³ÙŠØ© Ù„Ù„Ø·Ù„Ø§Ø¨",
    page_icon="ğŸ§ ",
    layout="centered"
)

st.title("ğŸ§  Ù…Ø¹Ø§Ù‹ Ù„ØªØ¹Ø²ÙŠØ² Ø§Ù„ØµØ­Ø© Ø§Ù„Ù†ÙØ³ÙŠØ© Ù„Ù„Ø·Ù„Ø§Ø¨ ")

# ---- Ø¥Ø¯Ø®Ø§Ù„ Ø§Ù„Ø±Ù‚Ù… Ø§Ù„ÙˆØ·Ù†ÙŠ Ù„Ù„Ø¨Ø­Ø« ----
national_id = st.text_input("Ø£Ø¯Ø®Ù„ Ø§Ù„Ø±Ù‚Ù… Ø§Ù„ÙˆØ·Ù†ÙŠ Ù„Ù„Ø·Ø§Ù„Ø¨ Ù„Ù„Ø¨Ø­Ø«:", key="national_id", max_chars=10)

if national_id:
    student = df_students[df_students["Ø§Ù„Ø±Ù‚Ù…_Ø§Ù„ÙˆØ·Ù†ÙŠ"] == national_id]
    if not student.empty:
        # Ø¥Ø°Ø§ ÙˆØ¬Ø¯ Ø§Ù„Ø·Ø§Ù„Ø¨
        st.success("ØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø·Ø§Ù„Ø¨!")
        st.markdown(f"**Ø§Ù„Ø§Ø³Ù…:** {student.iloc[0]['Ø§Ù„Ø§Ø³Ù…']}")
        st.markdown(f"**Ø§Ù„Ø¬Ù†Ø³:** {student.iloc[0]['Ø§Ù„Ø¬Ù†Ø³']}")
        st.markdown(f"**Ù…Ø³ØªÙˆÙ‰ Ø§Ù„Ø®Ø·ÙˆØ±Ø©:** {student.iloc[0]['Ù…Ø³ØªÙˆÙ‰_Ø§Ù„Ø®Ø·ÙˆØ±Ø©']}")
        st.markdown(f"**Ø§Ù„Ø¥Ø¬Ø±Ø§Ø¡ Ø§Ù„Ù…ÙˆØµÙ‰ Ø¨Ù‡:** {student.iloc[0]['Ø§Ù„Ø¥Ø¬Ø±Ø§Ø¡']}")
        st.markdown(f"**Ø§Ù„ØªÙˆØµÙŠØ§Øª:** {student.iloc[0]['Ø§Ù„ØªÙˆØµÙŠØ§Øª']}")
    else:
        st.warning("Ø§Ù„Ø±Ù‚Ù… Ø§Ù„ÙˆØ·Ù†ÙŠ ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯. Ø§Ù„Ø±Ø¬Ø§Ø¡ Ø¥Ø¯Ø®Ø§Ù„ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø·Ø§Ù„Ø¨:")
        
        # ---- Ø¥Ø¯Ø®Ø§Ù„ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø·Ø§Ù„Ø¨ Ø§Ù„Ø¬Ø¯ÙŠØ¯Ø© ----
        full_name = st.text_input("Ø§Ù„Ø§Ø³Ù… Ø§Ù„Ø±Ø¨Ø§Ø¹ÙŠ Ù„Ù„Ø·Ø§Ù„Ø¨")
        gender = st.selectbox("Ø§Ù„Ø¬Ù†Ø³", options=["Ø°ÙƒØ±", "Ø£Ù†Ø«Ù‰"])
        age = st.number_input("Ø§Ù„Ø¹Ù…Ø±", min_value=5, max_value=25, step=1)
        attendance = st.number_input("Ù†Ø³Ø¨Ø© Ø§Ù„Ø­Ø¶ÙˆØ± (%)", min_value=0, max_value=100, step=1)
        academic = st.number_input("Ø§Ù„Ù…Ø¹Ø¯Ù„ Ø§Ù„Ø£ÙƒØ§Ø¯ÙŠÙ…ÙŠ", min_value=0, max_value=100, step=1)
        counseling = st.number_input("Ø¹Ø¯Ø¯ Ø§Ù„Ø¬Ù„Ø³Ø§Øª Ø§Ù„Ø§Ø³ØªØ´Ø§Ø±ÙŠØ©", min_value=0, max_value=20, step=1)
        teacher_notes = st.text_area("Ù…Ù„Ø§Ø­Ø¸Ø§Øª Ø§Ù„Ù…Ø¹Ù„Ù…")

        # ---- Ø²Ø± Ø§Ù„ØªÙ†Ø¨Ø¤ ----
        if st.button("Ø­Ø³Ø§Ø¨ Ø§Ù„Ø¥Ø¬Ø±Ø§Ø¡"):

            # ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ø¬Ù†Ø³ Ø¥Ù„Ù‰ Ø±Ù‚Ù…
            gender_num = 0 if gender == "Ø°ÙƒØ±" else 1

            # ---- Ø­Ø³Ø§Ø¨ RiskLevel ----
            risk_level_str = get_risk_level(teacher_notes)
            risk_mapping = {"low": 0, "moderate": 1, "high": 2}
            risk_level_num = risk_mapping[risk_level_str]

            # ---- ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø¬Ø¯ÙŠØ¯Ø© Ø¥Ù„Ù‰ DataFrame Ù…Ø·Ø§Ø¨Ù‚ Ù„Ù„Ù€ features ----
            X_new = pd.DataFrame([{
                'StudentID': national_id,
                'Age': age,
                'GenderNum': gender_num,
                'AttendanceRate': attendance,
                'AcademicPerformance': academic,
                'CounselingSessions': counseling,
                'HotlineCalls': 0,
                'RiskLvlNum': risk_level_num
            }])

            # ---- Ø§Ù„ØªÙ†Ø¨Ø¤ Ø¨Ø§Ù„Ø¥Ø¬Ø±Ø§Ø¡ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù†Ù…ÙˆØ°Ø¬ Decision Tree ----
            action = dt_model.predict(X_new)[0]

            # ---- ØªÙˆÙ„ÙŠØ¯ ØªÙˆØµÙŠØ§Øª Ø¹Ø§Ù…Ø© Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„Ø¥Ø¬Ø±Ø§Ø¡ ----
            recommendations_dict = {
                "ØªØ¯Ø®Ù„ ÙÙˆØ±ÙŠ": "- Ø¥Ø®Ø·Ø§Ø± Ø§Ù„Ø£Ø®ØµØ§Ø¦ÙŠ Ø§Ù„Ù†ÙØ³ÙŠ/Ø§Ù„Ø§Ø¬ØªÙ…Ø§Ø¹ÙŠ ÙÙˆØ±Ù‹Ø§.\n- Ø§Ù„ØªÙˆØ§ØµÙ„ Ù…Ø¹ ÙˆÙ„ÙŠ Ø§Ù„Ø£Ù…Ø±.\n- Ù…ØªØ§Ø¨Ø¹Ø© Ù…Ø³ØªÙ…Ø±Ø© Ù„Ù„Ø·Ø§Ù„Ø¨.",
                "Ø¥Ø­Ø§Ù„Ø© Ø¥Ù„Ù‰ Ø¬Ù„Ø³Ø§Øª Ø¥Ø±Ø´Ø§Ø¯ÙŠØ©": "- Ø¬Ø¯ÙˆÙ„Ø© Ø¬Ù„Ø³Ø© Ø¥Ø±Ø´Ø§Ø¯ÙŠØ© Ù…Ø¹ Ø§Ù„Ø£Ø®ØµØ§Ø¦ÙŠ.\n- Ù…ØªØ§Ø¨Ø¹Ø© ØªÙ‚Ø¯Ù… Ø§Ù„Ø·Ø§Ù„Ø¨.",
                "Ù…ØªØ§Ø¨Ø¹Ø© Ù…Ù†ØªØ¸Ù…Ø©": "- Ø§Ù„Ø§Ø³ØªÙ…Ø±Ø§Ø± Ø¨Ø§Ù„Ù…ØªØ§Ø¨Ø¹Ø© Ø§Ù„Ø¯ÙˆØ±ÙŠØ© ÙˆØªØ´Ø¬ÙŠØ¹ Ø§Ù„Ø·Ø§Ù„Ø¨.",
                "Ù…ØªØ§Ø¨Ø¹Ø© Ø§Ù„Ù…Ø¹Ù„Ù… + Ù…ÙˆØ§Ø¯ ØªÙˆØ¹ÙˆÙŠØ©": "- ØªØ´Ø¬ÙŠØ¹ Ø§Ù„Ø·Ø§Ù„Ø¨ ÙˆØ§Ù„Ù…ØªØ§Ø¨Ø¹Ø© Ù…Ø¹ Ø§Ù„Ù…Ø¹Ù„Ù…ÙŠÙ†.\n- ØªÙ‚Ø¯ÙŠÙ… Ù…ÙˆØ§Ø¯ Ø¯Ø§Ø¹Ù…Ø© Ø¯Ø§Ø®Ù„ Ø§Ù„ØµÙ."
            }

            recommendations = recommendations_dict.get(action, "")

            st.success(f"Ø§Ù„Ø¥Ø¬Ø±Ø§Ø¡: {action}")
            st.markdown(f"Ø§Ù„ØªÙˆØµÙŠØ§Øª:\n{recommendations}")

            # ---- Ø¥Ø¶Ø§ÙØ© Ø§Ù„Ø·Ø§Ù„Ø¨ Ø§Ù„Ø¬Ø¯ÙŠØ¯ Ø¥Ù„Ù‰ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ÙˆØ­ÙØ¸Ù‡ ----
            new_row = {
                "Ø§Ù„Ø§Ø³Ù…": full_name,
                "Ø§Ù„Ø±Ù‚Ù…_Ø§Ù„ÙˆØ·Ù†ÙŠ": national_id,
                "Ø§Ù„Ø¬Ù†Ø³": gender,
                "Ø§Ù„Ø¹Ù…Ø±": age,
                "Ø§Ù„Ø­Ø¶ÙˆØ±": attendance,
                "Ø§Ù„Ù…Ø¹Ø¯Ù„_Ø§Ù„Ø£ÙƒØ§Ø¯ÙŠÙ…ÙŠ": academic,
                "Ø¹Ø¯Ø¯_Ø§Ù„Ø¬Ù„Ø³Ø§Øª": counseling,
                "Ù…Ù„Ø§Ø­Ø¸Ø§Øª": teacher_notes,
                "Ù…Ø³ØªÙˆÙ‰_Ø§Ù„Ø®Ø·ÙˆØ±Ø©": risk_level_str,  # Ø§Ù„Ù†Øµ
                "RiskLvlNum": risk_level_num,      # Ø§Ù„Ø±Ù‚Ù…
                "Ø§Ù„Ø¥Ø¬Ø±Ø§Ø¡": action,
                "Ø§Ù„ØªÙˆØµÙŠØ§Øª": recommendations
            }
            df_students = pd.concat([df_students, pd.DataFrame([new_row])], ignore_index=True)
            df_students.to_csv("students_data.csv", index=False)
            st.success("ØªÙ… Ø­ÙØ¸ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø·Ø§Ù„Ø¨ Ø¨Ù†Ø¬Ø§Ø­!")
